
import org.apache.spark.sql.SparkSession
import scala.math.random
import oracle.jdbc.driver.OracleDriver 

//fpms_staging.sql

object Spark_fpms_staging {
  def main(args: Array[String]) {
    // create Spark context with Spark configuration
    val spark = SparkSession
      .builder
      .appName("Spark Pi")
      .master("spark://192.168.2.151:7077")
      .getOrCreate()
      
// for BPMS_REQ_HEADER
val REQ_HEADER_DF = spark.read.parquet("/user/mapr/alexData/REQ_HEADER.parquet")
REQ_HEADER_DF.createOrReplaceTempView("REQ_HEADER")
var BPMS_REQ_HEADER_DF = spark.sql("SELECT ID, MODIFYDATE, MODIFYUSER, CREATEDATE, CREATEUSER, SYSSTATUS, CASE_TYPE, CASE_NO, CASE_DESCRIPTION, LAST_PROCEED_DATE, CURRENT_APPROVAL_DEADLINE, URGENCY_LEVEL, REQUESTER_USER_ID, REQUESTER_SECTION, REQUESTER_LOCATION, PROCESS_INSTANCE_ID, REQUEST_STATUS, REQUEST_STATUS_DATE, CURRENT_APPROVAL_AUTHORITY, ROUTING_PATH_ID, REQUESTER_FIRST_NAME, REQUESTER_LAST_NAME, CURRENT_REVIEW_ROUTING_SEQ, LAST_APPROVED_FNAME, LAST_APPROVED_LNAME, LAST_APPROVED_USER_ID, LAST_APPROVED_COMMITTEE, LAST_APPROVED_DATE FROM REQ_HEADER")
BPMS_REQ_HEADER_DF.write.format("parquet").mode("overwrite").save("/user/mapr/alexData/BPMS_REQ_HEADER.parquet")

// for BPMS_REQ_ROUTING_ENTRY

val REQ_ROUTING_ENTRY_DF = spark.read.parquet("/user/mapr/alexData/REQ_ROUTING_ENTRY.parquet")
REQ_ROUTING_ENTRY_DF.createOrReplaceTempView("REQ_ROUTING_ENTRY")
var BPMS_REQ_ROUTING_ENTRY_DF = spark.sql("SELECT ID, MODIFYDATE, MODIFYUSER, CREATEDATE, CREATEUSER, SYSSTATUS, CASE_TYPE, CASE_NO, CASE_DESCRIPTION, LAST_PROCEED_DATE, CURRENT_APPROVAL_DEADLINE, URGENCY_LEVEL, REQUESTER_USER_ID, REQUESTER_SECTION, REQUESTER_LOCATION, PROCESS_INSTANCE_ID, REQUEST_STATUS, REQUEST_STATUS_DATE, CURRENT_APPROVAL_AUTHORITY, ROUTING_PATH_ID, REQUESTER_FIRST_NAME, REQUESTER_LAST_NAME, CURRENT_REVIEW_ROUTING_SEQ, LAST_APPROVED_FNAME, LAST_APPROVED_LNAME, LAST_APPROVED_USER_ID, LAST_APPROVED_COMMITTEE, LAST_APPROVED_DATE FROM REQ_HEADER")
BPMS_REQ_ROUTING_ENTRY_DF.write.format("parquet").mode("overwrite").save("/user/mapr/alexData/BPMS_REQ_ROUTING_ENTRY.parquet")

// BPMS_SYS_BUDGET_HEAD_MASTER
val SYS_BUDGET_HEAD_MASTER_DF = spark.read.parquet("/user/mapr/alexData/SYS_BUDGET_HEAD_MASTER.parquet")
SYS_BUDGET_HEAD_MASTER_DF.createOrReplaceTempView("SYS_BUDGET_HEAD_MASTER")
var BPMS_SYS_BUDGET_HEAD_MASTER_DF = spark.sql("SELECT MODIFYDATE, MODIFYUSER, CREATEDATE, CREATEUSER, SYSSTATUS, CODE, DESCRIPTION, JOB_BUDGET, SYSTEM_BUDGET_HEAD, BUDGET_ACCOUNT FROM SYS_BUDGET_HEAD_MASTER")
BPMS_SYS_BUDGET_HEAD_MASTER_DF.write.format("parquet").mode("overwrite").save("/user/mapr/alexData/BPMS_SYS_BUDGET_HEAD_MASTER.parquet")

//BPMS_SYS_BUSINESS_UNIT_HEAD_MASTER
val SYS_BUSINESS_UNIT_HEAD_MASTER_DF = spark.read.parquet("/user/mapr/alexData/SYS_BUSINESS_UNIT_HEAD_MASTER.parquet")
SYS_BUSINESS_UNIT_HEAD_MASTER_DF.createOrReplaceTempView("SYS_BUSINESS_UNIT_HEAD_MASTER")
var BPMS_SYS_BUSINESS_UNIT_HEAD_MASTER_DF = spark.sql("SELECT MODIFYDATE, MODIFYUSER, CREATEDATE, CREATEUSER, SYSSTATUS, CODE, DESCRIPTION FROM SYS_BUSINESS_UNIT_HEAD_MASTER")
BPMS_SYS_BUSINESS_UNIT_HEAD_MASTER_DF.write.format("parquet").mode("overwrite").save("/user/mapr/alexData/BPMS_SYS_BUSINESS_UNIT_HEAD_MASTER.parquet")
    
//BPMS_SYS_BUSINESS_UNIT_MASTER
val SYS_BUSINESS_UNIT_MASTER_DF = spark.read.parquet("/user/mapr/alexData/SYS_BUSINESS_UNIT_MASTER.parquet")
SYS_BUSINESS_UNIT_MASTER_DF.createOrReplaceTempView("SYS_BUSINESS_UNIT_MASTER")
var BPMS_SYS_BUSINESS_UNIT_MASTER_DF = spark.sql("SELECT BU.MODIFYDATE, BU.MODIFYUSER, BU.CREATEDATE, BU.CREATEUSER, BU.SYSSTATUS, BU.CODE, BU.DESCRIPTION, BU.STATUS, BU.BUSINESS_UNIT_HEAD_CODE, BU.COMPANY_CODE, BU.ORGANIZATION_UNIT_CODE, BU.PROJECT_CODE, BU.PROPERTY_TYPE_CODE, BU.BUSINESS_TYPE_CODE, BU.COMPLETE, BU.BUDGET_CHECKING_KEY FROM SYS_BUSINESS_UNIT_MASTER BU")
BPMS_SYS_BUSINESS_UNIT_MASTER_DF.write.format("parquet").mode("overwrite").save("/user/mapr/alexData/BPMS_SYS_BUSINESS_UNIT_MASTER.parquet")

//BPMS_SYS_COMMITTEE_MASTER
val SYS_COMMITTEE_MASTER_DF = spark.read.parquet("/user/mapr/alexData/SYS_COMMITTEE_MASTER.parquet")
SYS_COMMITTEE_MASTER_DF.createOrReplaceTempView("SYS_COMMITTEE_MASTER")
var BPMS_SYS_COMMITTEE_MASTER_DF = spark.sql("SELECT MODIFYDATE, MODIFYUSER, CREATEDATE, CREATEUSER, SYSSTATUS, CODE, DESCRIPTION, AUTHORITY_LEVEL_CODE FROM  SYS_COMMITTEE_MASTER")
BPMS_SYS_COMMITTEE_MASTER_DF.write.format("parquet").mode("overwrite").save("/user/mapr/alexData/BPMS_SYS_COMMITTEE_MASTER.parquet")

//BPMS_SYS_COMPANY_CATEGORY_MASTER
val SYS_COMPANY_CATEGORY_MASTER_DF = spark.read.parquet("/user/mapr/alexData/SYS_COMPANY_CATEGORY_MASTER.parquet")
SYS_COMPANY_CATEGORY_MASTER_DF.createOrReplaceTempView("SYS_COMPANY_CATEGORY_MASTER")
var BPMS_SYS_COMPANY_CATEGORY_MASTER_DF = spark.sql("SELECT MODIFYDATE, MODIFYUSER, CREATEDATE, CREATEUSER, SYSSTATUS, MANAGED_PROPERTY, CODE, DESCRIPTION, START_MONTH FROM SYS_COMPANY_CATEGORY_MASTER")
BPMS_SYS_COMPANY_CATEGORY_MASTER_DF.write.format("parquet").mode("overwrite").save("/user/mapr/alexData/BPMS_SYS_COMPANY_CATEGORY_MASTER.parquet")

//BPMS_SYS_TENDER_TYPE_MASTER
val SYS_TENDER_TYPE_MASTER_DF = spark.read.parquet("/user/mapr/alexData/SYS_TENDER_TYPE_MASTER.parquet")
SYS_TENDER_TYPE_MASTER_DF.createOrReplaceTempView("SYS_TENDER_TYPE_MASTER")
var BPMS_SYS_TENDER_TYPE_MASTER_DF = spark.sql("SELECT ID, MODIFYDATE, MODIFYUSER, CREATEDATE, CREATEUSER, SYSSTATUS, NAME, DESCRIPTION, APPROVALSUBTYPECODE FROM SYS_TENDER_TYPE_MASTER")
BPMS_SYS_TENDER_TYPE_MASTER_DF.write.format("parquet").mode("overwrite").save("/user/mapr/alexData/BPMS_SYS_TENDER_TYPE_MASTER.parquet")

           
    spark.stop()
  }
}